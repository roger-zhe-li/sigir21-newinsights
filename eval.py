# -*- coding: utf-8 -*-
"""eval.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nQcUfPmZE76k1L_zkRgJhXg3KiuvofmQ
"""

import numpy as np
import torch
from list_loss import *
import torchsnooper
# from sklearn.metrics import average_precision_score as ap

def hit(gt):
    for gt_item in gt:
        if gt_item == 1:
            return 1
    return 0


def dcg_at_k(gt, k):
    return np.sum((np.power(2, gt[: k]) - 1) / np.log2(np.arange(2, k + 2)))

def dcg(gt):
    return np.sum((np.power(2, gt) - 1) / np.log2(np.arange(2, len(gt) + 2)))

def evaluation(model, test_loader, max_rating, device, k, p, n_item):
    model.eval()
    NDCG_at_5, NDCG, RR, AP, RBP_80, RBP_90, RBP_95 = [], [], [], [], [], [], []
    
    for user, items, binary_rels, scale_rels in test_loader:
        user, items, binary_rels, scale_rels = user.to(device), items.to(device), binary_rels.to(device), scale_rels.to(device)
        for i in range(len(user)):
            gt_items = []
            u = user[i]
            item = items[i]
            binary_rel = binary_rels[i]
            scale_rel = scale_rels[i]

            prediction_i = model(u, item, -1, mode='test')

            # ratings, indices = torch.topk(prediction_i, k)
            ratings, indices = torch.topk(prediction_i, len(item))
            
            recommends = torch.take(item, indices).cpu().numpy().tolist()
#             print(u, recommends)
            binary_gt = binary_rel[indices].cpu().numpy()
            scale_gt = scale_rel[indices].cpu().numpy()
#             gt = recommends      
#             gt = [gt[j].cpu().numpy().tolist() for j in range(len(gt))]
            
            recommends = list(filter(lambda x: x != n_item, recommends))
            binary_gt = list(filter(lambda x: x != 20, binary_gt))
            scale_gt = list(filter(lambda x: x != 20, scale_gt))
            if len(scale_gt) < 5:
                scale_gt = scale_gt + [0] * (5 - len(scale_gt))


            non_zero = np.asarray(binary_gt).nonzero()[0]

            # # with cutoff
            # rr = 1. / (non_zero[0] + 1) if non_zero.size else 0.
            # ap = (binary_gt * np.cumsum(binary_gt) / (1 + np.arange(k))).mean()
            # rbp = (1 - p) * (binary_gt * np.power(p, range(k))).sum()

            # no cutoff
            rr = 1. / (non_zero[0] + 1) if non_zero.size else 0.
            ap = (binary_gt * np.cumsum(binary_gt) / (1 + np.arange(len(binary_gt))))
            ap = ap[np.nonzero(ap)].mean()
            rbp_80 = (1 - 0.8) * (binary_gt * np.power(0.8, range(len(binary_gt)))).sum()
            rbp_90 = (1 - 0.9) * (binary_gt * np.power(0.9, range(len(binary_gt)))).sum()
            rbp_95 = (1 - 0.95) * (binary_gt * np.power(0.95, range(len(binary_gt)))).sum()
        
        ###################################################### 
        # dcg with cutoff
            # full_mark = [max_rating] * k
        # dcg without cutoff
            idcg_gt = np.sort(scale_gt)[::-1]
            # score = 0
            # for j in range(len(item)):
            #     score = score + (np.power(2, idcg_gt[j]) - 1) / np.log2(j+2)
        #######################################################
#             print(hit(gt))
#             print(dcg(gt))
            # HR.append(hit(binary_gt))
            # NDCG.append(dcg(scale_gt) / score)
            NDCG_at_5.append(dcg_at_k(scale_gt, k) / dcg_at_k(idcg_gt, k))
            NDCG.append(dcg(scale_gt) / dcg(idcg_gt))
            RR.append(rr)
            AP.append(ap)
            RBP_80.append(rbp_80)
            RBP_90.append(rbp_90)
            RBP_95.append(rbp_95)

#             print(len(NDCG))
    
    # print("HR = %.4f" % np.mean(HR))
    print("NDCG@5 = %.4f" % np.mean(NDCG_at_5))
    print("NDCG = %.4f" % np.mean(NDCG))
    print("MRR = %.4f" % np.mean(RR))
    print("MAP = %.4f" % np.mean(AP))
    print("RBP_80 = %.4f" % np.mean(RBP_80))
    print("RBP_90 = %.4f" % np.mean(RBP_90))
    print("RBP_95 = %.4f" % np.mean(RBP_95))
        
    return NDCG_at_5, NDCG, RR, AP, RBP_80, RBP_90, RBP_95, np.mean(NDCG_at_5), np.mean(NDCG), np.mean(RR), np.mean(AP), np.mean(RBP_80), np.mean(RBP_90), np.mean(RBP_95)

# def evaluation_bpr(model, test_loader, max_rating, device, k, p=0.9):
#     model.eval()
#     HR, NDCG, RR, AP, RBP = [], [], [], [], []
    
#     for user, items, binary_rels, scale_rels in test_loader:
#         user, items, binary_rels, scale_rels = user.to(device), items.to(device), binary_rels.to(device), scale_rels.to(device)
#         for i in range(len(user)):
#             gt_items = []
#             u = user[i]
#             item = items[i]
#             binary_rel = binary_rels[i]
#             scale_rel = scale_rels[i]

#             prediction_i, prediction_j = model(u, item, item)


#             ratings, indices = torch.topk(prediction_i, k)
            
#             recommends = torch.take(item, indices).cpu().numpy().tolist()
# #             print(u, recommends)
#             binary_gt = binary_rel[indices].cpu().numpy()
#             scale_gt = scale_rel[indices].cpu().numpy()
# #             gt = recommends      
# #             gt = [gt[j].cpu().numpy().tolist() for j in range(len(gt))]
#             non_zero = np.asarray(binary_gt).nonzero()[0]
#             rr = 1. / (non_zero[0] + 1) if non_zero.size else 0.
#             ap = (binary_gt * np.cumsum(binary_gt) / (1 + np.arange(k))).mean()
#             rbp = (1 - p) * (binary_gt * np.power(p, range(k))).sum()
        
#         ###################################################### 
#             full_mark = [max_rating] * k
#             score = 0
#             for j in range(len(full_mark)):
#                 score = score + np.power(2, max_rating) / np.log2(j+2)
#         #######################################################
# #             print(hit(gt))
# #             print(dcg(gt))
#             HR.append(hit(binary_gt))
#             NDCG.append(dcg(scale_gt) / score)
#             RR.append(rr)
#             AP.append(ap)
#             RBP.append(rbp)

# #             print(len(NDCG))
    
#     print("HR = %.4f" % np.mean(HR))
#     print("NDCG = %.4f" % np.mean(NDCG))
#     print("MRR = %.4f" % np.mean(RR))
#     print("MAP = %.4f" % np.mean(AP))
#     print("RBP = %.4f" % np.mean(RBP))
        
#     return np.mean(HR), np.mean(NDCG), np.mean(RR), np.mean(AP), np.mean(RBP)

