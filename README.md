# New Insights into Metric Optimization for Ranking-based Recommendation

This is our implementation and experimental data for the paper:

Roger Zhe Li, Juli√°n Urbano, Alan Hanjalic (2021). New Insights into Metric Optimization for Ranking-based Recommendation. In Proceedings of SIGIR'21, Virtual Event, Canada, July 11-15, 2021.

**Please cite our SIGIR'21 paper if you use our code and data. Thanks!** 

Author: Roger Zhe Li (http://www.zhe-li.me)

## Environment Settings
We use PyTorch 1.6.0 as the main deep learning framework for implementation. <br/>
The debugging stage relies much on the Torchsnooper package. <br/>
The dataset processing and splitting stage is conducted with the dependency of [PyLensKit](https://lenskit.org/). 

Figures and related analysis in the paper are mainly implemented in R.


## File and Folder Structure

[./proc_cite.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/proc_cite.py): processing CiteULike-a dataset; <br/>
[./proc_trust.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/proc_trust.py): processing Epinions dataset; <br/>
[./proc_amazon.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/proc_amazon.py): processing Amazon datasets. <br/>

[./data](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/data): Store the processed four datasets used for experimentation; <br/>
[./results](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/results): Store the original results of listwise recommendation models; <br/>
[./lambda_results](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/lambda_results): Store the original results of pairwise (lambdaRank) recommendation models; <br/>
[./analysis](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/analysis): Store the code and assisting files for analysis conducted in the paper; <br/>
[./figures](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/figures): Store the figures generated by code under the analysis folder, which are further used in the paper. <br/>
[./listMF.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/listMF.py): Main file for listwise recommendation; <br/>
[./lambdaMF.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/lambdaMF.py): Main file for pairwise recommendation.

All other .py files are imported in the main files. See below for a brief introduction.

[./model.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/model.py): Matrix Factorization module for listwise use; <br/>
[./model_lambda.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/model_lambda.py): Matrix Factorization module for pairwise use. The same to that for listwise, but it is still made separate for possible individual changes as per LambdaRank.  <br/>
[./list_loss.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/list_loss.py): Smooth listwise loss functions used for optimizing nDCG, AP, RR and nRBP (independent of p);  <br/>
[./lambda_loss.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/lambda_loss.py): Pairwise loss functions based on LambdaRank used for optimizing nDCG, AP, RR and nRBP with diffrent p values (0.8, 0.9, 0.95);  <br/>
[./Dataset.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/Dataset.py): Negative sampling and dataloader preparation for PyTorch;  <br/>
[./eval.py](https://github.com/roger-zhe-li/sigir21-newinsights/tree/main/eval.py): Module used for evaluation on the test set. 


## Example to run the code
The instruction of commands has been clearly stated in the code (see the parse_args function). 

Run listwise recommenders:

```
python3 listMF.py --dataset Home_and_Kitchen --batch_size 256 --lr 0.001 --loss_type ap  --th 4  --frac 1  --emb_size 32  --fold 0
```
Run LambdaRank:

```
python3 lambdaMF.py --dataset citeulike --p 0.8 --batch_size 16 --lr 0.001  --loss_type lambda_rbp  --th 0 --frac 2  --emb_size 32  --fold 2
```
To generate analytical figures, please run the code under the ./analysis folder. <br/>
To get the number of positive items each user interacted with, run the code as

```
python3 ./analysis/user_count.py
```
Output files will be also under the same folder. <br/>
All data used for figure plotting are generated via the aggregation script user the ./analysis folder. It is worth noting that we also provide some preliminary results on different embedding sizes (e.g., 8, 16, 64 and 128) and learning rates in addition to what we finally used for full experimentation. They are later discarded in the figure generation R scripts. For getting the listwise results, run the aggredation code as
```
python3 ./analysis/data_aggregation.py --res_path ../results --dataset Epinions
```
For getting the pairwise counterpart, run the code as
```
python3 ./analysis/data_aggregation.py --res_path ../lambda_results --dataset Epinions
```

Figures appeared in the paper are generated through R scripts under the ./analysis folder, and later stored in the ./figures folder. To generate the figures, please run two R scripts in order:

```
Rscript ./analysis/figures_runfirst.R <br/>
Rscript ./analysis/figures.R
```
### Dataset
We provide four processed datasets with three different train-test splits under the ./data folder. The processing methods are stated in the paper. In brief, we have two datasets with unary feedback, namely CiteULike-a and Epinions; we also provide 2 domains, i.e., Sports & Outdoors and Home & Kitchen from the Amazon Review dataset. 

The original [CiteULike-a](https://github.com/roger-zhe-li/sigir21-newinsights/blob/main/data/citeulike/users.dat) and [Epinions](https://github.com/roger-zhe-li/sigir21-newinsights/blob/main/data/Epinions/trust_data.txt) datasets are available in this repo. For two Amazon datasets, the original version is too large to be available here. You can find them [here](https://nijianmo.github.io/amazon/index.html).


### Cite

Please cite our SIGIR'21 paper if you use the code.

```
@inproceedings{DBLP:conf/sigir/LiUH21,
  author    = {Roger Zhe Li and
               Juli{\'{a}}n Urbano and
               Alan Hanjalic},
  title     = {New Insights into Metric Optimization for Ranking-based Recommendation},
  booktitle = {{SIGIR}},
  pages     = {932--941},
  publisher = {{ACM}},
  year      = {2021}
}
```


## License
* The paper is licensed under a [Creative Commons Attribution International 4.0 License](https://creativecommons.org/licenses/by/4.0/).
* Databases and their contents are distributed under the terms of the [Creative Commons Attribution-ShareAlike 4.0 International License](https://creativecommons.org/licenses/by-sa/4.0/).
* Software is distributed under the terms of the [MIT License](https://opensource.org/licenses/MIT).



Last Update Date: July 6, 2021
